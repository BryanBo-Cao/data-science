{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "% matplotlib inline\n",
    "# Always make it pretty.\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data from file\n",
    "df = pd.read_csv('../data/df_model_final_bryanbc_frequency_recency_playtime_songplay80pcnt_listenthrehold.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>label</th>\n",
       "      <th>freq_P_last_1</th>\n",
       "      <th>freq_P_last_3</th>\n",
       "      <th>freq_P_last_7</th>\n",
       "      <th>freq_P_last_14</th>\n",
       "      <th>freq_P_last_30</th>\n",
       "      <th>freq_D_last_1</th>\n",
       "      <th>freq_D_last_3</th>\n",
       "      <th>freq_D_last_7</th>\n",
       "      <th>...</th>\n",
       "      <th>song_play_80_pcnt_3</th>\n",
       "      <th>song_play_80_pcnt_7</th>\n",
       "      <th>song_play_80_pcnt_14</th>\n",
       "      <th>song_play_80_pcnt_30</th>\n",
       "      <th>listen_threhold_1</th>\n",
       "      <th>listen_threhold_3</th>\n",
       "      <th>listen_threhold_7</th>\n",
       "      <th>listen_threhold_14</th>\n",
       "      <th>listen_threhold_30</th>\n",
       "      <th>device_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.317830e+05</td>\n",
       "      <td>431783.000000</td>\n",
       "      <td>431783.000000</td>\n",
       "      <td>431783.000000</td>\n",
       "      <td>431783.000000</td>\n",
       "      <td>431783.000000</td>\n",
       "      <td>431783.000000</td>\n",
       "      <td>431783.000000</td>\n",
       "      <td>431783.000000</td>\n",
       "      <td>431783.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>431783.000000</td>\n",
       "      <td>431783.000000</td>\n",
       "      <td>431783.00000</td>\n",
       "      <td>431783.000000</td>\n",
       "      <td>431783.000000</td>\n",
       "      <td>431783.000000</td>\n",
       "      <td>431783.000000</td>\n",
       "      <td>431783.000000</td>\n",
       "      <td>431783.000000</td>\n",
       "      <td>431783.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.669634e+08</td>\n",
       "      <td>0.270696</td>\n",
       "      <td>9.324494</td>\n",
       "      <td>28.748670</td>\n",
       "      <td>63.558292</td>\n",
       "      <td>134.748466</td>\n",
       "      <td>313.659123</td>\n",
       "      <td>0.298275</td>\n",
       "      <td>0.896747</td>\n",
       "      <td>2.075756</td>\n",
       "      <td>...</td>\n",
       "      <td>15.744066</td>\n",
       "      <td>34.417677</td>\n",
       "      <td>73.03215</td>\n",
       "      <td>163.273737</td>\n",
       "      <td>6.818603</td>\n",
       "      <td>21.193535</td>\n",
       "      <td>46.574867</td>\n",
       "      <td>99.013062</td>\n",
       "      <td>226.644560</td>\n",
       "      <td>1.820602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.213354e+07</td>\n",
       "      <td>0.444320</td>\n",
       "      <td>24.717553</td>\n",
       "      <td>58.114771</td>\n",
       "      <td>109.340304</td>\n",
       "      <td>203.903974</td>\n",
       "      <td>399.449389</td>\n",
       "      <td>8.051736</td>\n",
       "      <td>10.887892</td>\n",
       "      <td>15.980681</td>\n",
       "      <td>...</td>\n",
       "      <td>35.086951</td>\n",
       "      <td>66.951553</td>\n",
       "      <td>127.12492</td>\n",
       "      <td>247.366983</td>\n",
       "      <td>16.693362</td>\n",
       "      <td>42.101375</td>\n",
       "      <td>80.294364</td>\n",
       "      <td>151.936400</td>\n",
       "      <td>296.364984</td>\n",
       "      <td>0.385570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.233300e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.679551e+08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.683425e+08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>24.00000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.686937e+08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>403.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>88.00000</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>287.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.692584e+08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>916.000000</td>\n",
       "      <td>1148.000000</td>\n",
       "      <td>1504.000000</td>\n",
       "      <td>2157.000000</td>\n",
       "      <td>3762.000000</td>\n",
       "      <td>1463.000000</td>\n",
       "      <td>1463.000000</td>\n",
       "      <td>1463.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>463.000000</td>\n",
       "      <td>906.000000</td>\n",
       "      <td>1326.00000</td>\n",
       "      <td>2581.000000</td>\n",
       "      <td>461.000000</td>\n",
       "      <td>502.000000</td>\n",
       "      <td>953.000000</td>\n",
       "      <td>1408.000000</td>\n",
       "      <td>2847.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                uid          label  freq_P_last_1  freq_P_last_3  \\\n",
       "count  4.317830e+05  431783.000000  431783.000000  431783.000000   \n",
       "mean   1.669634e+08       0.270696       9.324494      28.748670   \n",
       "std    1.213354e+07       0.444320      24.717553      58.114771   \n",
       "min    1.233300e+04       0.000000       0.000000       0.000000   \n",
       "25%    1.679551e+08       0.000000       0.000000       0.000000   \n",
       "50%    1.683425e+08       0.000000       0.000000       4.000000   \n",
       "75%    1.686937e+08       1.000000       8.000000      32.000000   \n",
       "max    1.692584e+08       1.000000     916.000000    1148.000000   \n",
       "\n",
       "       freq_P_last_7  freq_P_last_14  freq_P_last_30  freq_D_last_1  \\\n",
       "count  431783.000000   431783.000000   431783.000000  431783.000000   \n",
       "mean       63.558292      134.748466      313.659123       0.298275   \n",
       "std       109.340304      203.903974      399.449389       8.051736   \n",
       "min         0.000000        0.000000        0.000000       0.000000   \n",
       "25%         0.000000        8.000000       62.000000       0.000000   \n",
       "50%        21.000000       60.000000      175.000000       0.000000   \n",
       "75%        78.000000      172.000000      403.000000       0.000000   \n",
       "max      1504.000000     2157.000000     3762.000000    1463.000000   \n",
       "\n",
       "       freq_D_last_3  freq_D_last_7      ...        song_play_80_pcnt_3  \\\n",
       "count  431783.000000  431783.000000      ...              431783.000000   \n",
       "mean        0.896747       2.075756      ...                  15.744066   \n",
       "std        10.887892      15.980681      ...                  35.086951   \n",
       "min         0.000000       0.000000      ...                   0.000000   \n",
       "25%         0.000000       0.000000      ...                   0.000000   \n",
       "50%         0.000000       0.000000      ...                   1.000000   \n",
       "75%         0.000000       0.000000      ...                  16.000000   \n",
       "max      1463.000000    1463.000000      ...                 463.000000   \n",
       "\n",
       "       song_play_80_pcnt_7  song_play_80_pcnt_14  song_play_80_pcnt_30  \\\n",
       "count        431783.000000          431783.00000         431783.000000   \n",
       "mean             34.417677              73.03215            163.273737   \n",
       "std              66.951553             127.12492            247.366983   \n",
       "min               0.000000               0.00000              0.000000   \n",
       "25%               0.000000               1.00000             19.000000   \n",
       "50%               8.000000              24.00000             76.000000   \n",
       "75%              39.000000              88.00000            201.000000   \n",
       "max             906.000000            1326.00000           2581.000000   \n",
       "\n",
       "       listen_threhold_1  listen_threhold_3  listen_threhold_7  \\\n",
       "count      431783.000000      431783.000000      431783.000000   \n",
       "mean            6.818603          21.193535          46.574867   \n",
       "std            16.693362          42.101375          80.294364   \n",
       "min             0.000000           0.000000           0.000000   \n",
       "25%             0.000000           0.000000           0.000000   \n",
       "50%             0.000000           3.000000          15.000000   \n",
       "75%             6.000000          24.000000          57.000000   \n",
       "max           461.000000         502.000000         953.000000   \n",
       "\n",
       "       listen_threhold_14  listen_threhold_30    device_type  \n",
       "count       431783.000000       431783.000000  431783.000000  \n",
       "mean            99.013062          226.644560       1.820602  \n",
       "std            151.936400          296.364984       0.385570  \n",
       "min              0.000000            0.000000       0.000000  \n",
       "25%              5.000000           42.000000       2.000000  \n",
       "50%             43.000000          125.000000       2.000000  \n",
       "75%            125.000000          287.000000       2.000000  \n",
       "max           1408.000000         2847.000000       2.000000  \n",
       "\n",
       "[8 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show summary stats\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['device_type_1'] = (df['device_type'] == 1).astype(int)\n",
    "df['device_type_2'] = (df['device_type'] == 2).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_features = list(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['freq_P_last_1',\n",
       " 'freq_P_last_3',\n",
       " 'freq_P_last_7',\n",
       " 'freq_P_last_14',\n",
       " 'freq_P_last_30',\n",
       " 'freq_D_last_1',\n",
       " 'freq_D_last_3',\n",
       " 'freq_D_last_7',\n",
       " 'freq_D_last_14',\n",
       " 'freq_D_last_30',\n",
       " 'recency',\n",
       " 'total_play_time_1',\n",
       " 'total_play_time_3',\n",
       " 'total_play_time_7',\n",
       " 'total_play_time_14',\n",
       " 'total_play_time_30',\n",
       " 'song_play_80_pcnt_1',\n",
       " 'song_play_80_pcnt_3',\n",
       " 'song_play_80_pcnt_7',\n",
       " 'song_play_80_pcnt_14',\n",
       " 'song_play_80_pcnt_30',\n",
       " 'listen_threhold_1',\n",
       " 'listen_threhold_3',\n",
       " 'listen_threhold_7',\n",
       " 'listen_threhold_14',\n",
       " 'listen_threhold_30',\n",
       " 'device_type_1',\n",
       " 'device_type_2']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features.remove('uid')\n",
    "selected_features.remove('label')\n",
    "selected_features.remove('device_type')\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df[selected_features]\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(431783, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "5    0\n",
       "6    0\n",
       "7    0\n",
       "8    0\n",
       "9    0\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's Train-test split the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import train test split function from sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define function to perform train, test, and get model performance\n",
    "def train_test_model(clf, X_train, y_train, X_test, y_test):\n",
    "    # Fit a model by providing X and y from training set\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make prediction on the training data\n",
    "    y_train_pred = clf.predict(X_train)\n",
    "    p_train_pred = clf.predict_proba(X_train)[:,1]\n",
    "\n",
    "    # Make predictions on test data\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    p_test_pred = clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    # print model results\n",
    "    get_performance_metrics(y_train, p_train_pred, y_test, p_test_pred)\n",
    "    plot_roc_curve(y_train, p_train_pred, y_test, p_test_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the metric scores for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def plot_roc_curve(y_train, y_train_pred, y_test, y_test_pred):\n",
    "    roc_auc_train = roc_auc_score(y_train, y_train_pred)\n",
    "    fpr_train, tpr_train, _ = roc_curve(y_train, y_train_pred)\n",
    "\n",
    "    roc_auc_test = roc_auc_score(y_test, y_test_pred)\n",
    "    fpr_test, tpr_test, _ = roc_curve(y_test, y_test_pred)\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr_train, tpr_train, color='green',\n",
    "             lw=lw, label='ROC Train (AUC = %0.4f)' % roc_auc_train)\n",
    "    plt.plot(fpr_test, tpr_test, color='darkorange',\n",
    "             lw=lw, label='ROC Test (AUC = %0.4f)' % roc_auc_test)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import metrics functions from sklearn\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Helper method to print metric scores    \n",
    "def get_performance_metrics(y_train, y_train_pred, y_test, y_test_pred, threshold=0.5):\n",
    "    metric_names = ['AUC','Accuracy','Precision','Recall','f1-score']\n",
    "    metric_values_train = [roc_auc_score(y_train, y_train_pred),\n",
    "                    accuracy_score(y_train, y_train_pred>threshold),\n",
    "                    precision_score(y_train, y_train_pred>threshold),\n",
    "                    recall_score(y_train, y_train_pred>threshold),\n",
    "                    f1_score(y_train, y_train_pred>threshold)\n",
    "                   ]\n",
    "    metric_values_test = [roc_auc_score(y_test, y_test_pred),\n",
    "                    accuracy_score(y_test, y_test_pred>threshold),\n",
    "                    precision_score(y_test, y_test_pred>threshold),\n",
    "                    recall_score(y_test, y_test_pred>threshold),\n",
    "                    f1_score(y_test, y_test_pred>threshold)\n",
    "                   ]\n",
    "    all_metrics = pd.DataFrame({'metrics':metric_names,\n",
    "                                'train':metric_values_train,\n",
    "                                'test':metric_values_test},columns=['metrics','train','test']).set_index('metrics')\n",
    "    print(all_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import logistic regression from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize model by providing parameters\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "clf = LogisticRegression(C=1.0, penalty='l2')\n",
    "# Fit a model by providing X and y from training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Train test model\n",
    "train_test_model(clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging\n",
    "### Single Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(max_depth=20,min_samples_leaf=10)\n",
    "\n",
    "# Fit a model by providing X and y from training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Train test model\n",
    "train_test_model(clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_feature_importance = pd.DataFrame()\n",
    "df_feature_importance['feature'] = selected_features\n",
    "df_feature_importance['importance'] = clf.feature_importances_\n",
    "df_feature_importance.sort_values('importance',inplace=True)\n",
    "\n",
    "ax = df_feature_importance.plot.barh()\n",
    "t = np.arange(len(df_feature_importance['feature']))\n",
    "ax.set_yticks(t)\n",
    "ax.set_yticklabels(df_feature_importance['feature'])\n",
    "plt.show()\n",
    "plt.figure(figsize=(400,300)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagged Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html \n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "base_classifier = DecisionTreeClassifier(max_depth=20,min_samples_leaf=10)\n",
    "\n",
    "# Choose some parameter combinations to try\n",
    "parameters = {\n",
    "              'base_estimator':base_classifier,\n",
    "              'n_estimators': 50,\n",
    "              'n_jobs': -1\n",
    "              }\n",
    "\n",
    "clf = BaggingClassifier(**parameters)\n",
    "\n",
    "# Train test model\n",
    "train_test_model(clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_feature_importance = pd.DataFrame()\n",
    "df_feature_importance['feature'] = selected_features\n",
    "df_feature_importance['importance'] = clf.feature_importances_\n",
    "df_feature_importance.sort_values('importance',inplace=True)\n",
    "\n",
    "ax = df_feature_importance.plot.barh()\n",
    "t = np.arange(len(df_feature_importance['feature']))\n",
    "ax.set_yticks(t)\n",
    "ax.set_yticklabels(df_feature_importance['feature'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "parameters = {\n",
    "    #'weights':'distance',\n",
    "    'n_neighbors':3,\n",
    "    'leaf_size':10\n",
    "}\n",
    "base_classifier = KNeighborsClassifier(**parameters)\n",
    "clf = base_classifier\n",
    "\n",
    "# Train test model\n",
    "train_test_model(clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_feature_importance = pd.DataFrame()\n",
    "df_feature_importance['feature'] = selected_features\n",
    "df_feature_importance['importance'] = clf.feature_importances_\n",
    "df_feature_importance.sort_values('importance',inplace=True)\n",
    "\n",
    "ax = df_feature_importance.plot.barh()\n",
    "t = np.arange(len(df_feature_importance['feature']))\n",
    "ax.set_yticks(t)\n",
    "ax.set_yticklabels(df_feature_importance['feature'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagged KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Choose some parameter combinations to try\n",
    "parameters = {\n",
    "              'base_estimator':base_classifier,\n",
    "              'n_estimators': 30,\n",
    "              'n_jobs': -1\n",
    "              }\n",
    "\n",
    "clf = BaggingClassifier(**parameters)\n",
    "\n",
    "# Train test model\n",
    "train_test_model(clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_feature_importance = pd.DataFrame()\n",
    "df_feature_importance['feature'] = selected_features\n",
    "df_feature_importance['importance'] = clf.feature_importances_\n",
    "df_feature_importance.sort_values('importance',inplace=True)\n",
    "\n",
    "ax = df_feature_importance.plot.barh()\n",
    "t = np.arange(len(df_feature_importance['feature']))\n",
    "ax.set_yticks(t)\n",
    "ax.set_yticklabels(df_feature_importance['feature'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Choose some parameter combinations to try\n",
    "parameters = {'n_estimators': 50,\n",
    "              'max_features': 'auto',\n",
    "              'criterion': 'gini',\n",
    "              'max_depth': 20,\n",
    "              'min_samples_split': 2,\n",
    "              'min_samples_leaf': 20,\n",
    "              'random_state': 0,\n",
    "              'n_jobs': -1\n",
    "              }\n",
    "\n",
    "clf = RandomForestClassifier(**parameters)\n",
    "\n",
    "# Fit a model by providing X and y from training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Train test model\n",
    "train_test_model(clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_feature_importance = pd.DataFrame()\n",
    "df_feature_importance['feature'] = selected_features\n",
    "df_feature_importance['importance'] = clf.feature_importances_\n",
    "df_feature_importance.sort_values('importance',inplace=True)\n",
    "\n",
    "ax = df_feature_importance.plot.barh()\n",
    "t = np.arange(len(df_feature_importance['feature']))\n",
    "ax.set_yticks(t)\n",
    "ax.set_yticklabels(df_feature_importance['feature'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Choose some parameter combinations to try\n",
    "parameters = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 5,\n",
    "    'learning_rate': 0.1,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "# parameters = {\n",
    "#     'n_estimators': 50,\n",
    "#     'max_depth': 5,\n",
    "#     'learning_rate': 0.2,\n",
    "#     'subsample': 0.7,\n",
    "#     'max_features':0.8,\n",
    "#     'random_state': 42\n",
    "# }\n",
    "\n",
    "clf = GradientBoostingClassifier(**parameters)\n",
    "\n",
    "# Train test model\n",
    "train_test_model(clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_feature_importance = pd.DataFrame()\n",
    "df_feature_importance['feature'] = selected_features\n",
    "df_feature_importance['importance'] = clf.feature_importances_\n",
    "df_feature_importance.sort_values('importance',inplace=True)\n",
    "\n",
    "ax = df_feature_importance.plot.barh()\n",
    "t = np.arange(len(df_feature_importance['feature']))\n",
    "ax.set_yticks(t)\n",
    "ax.set_yticklabels(df_feature_importance['feature'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Choose some parameter combinations to try\n",
    "parameters = {\n",
    "    'solver':'adam', \n",
    "    'activation':'relu',\n",
    "    'alpha':1e-5, #increase alpha->increase penalty :: http://scikit-learn.org/stable/auto_examples/neural_networks/plot_mlp_alpha.html#sphx-glr-auto-examples-neural-networks-plot-mlp-alpha-py\n",
    "    'hidden_layer_sizes':(5,5), \n",
    "    'learning_rate':'adaptive',\n",
    "    'random_state':1\n",
    "    }\n",
    "clf = MLPClassifier(**parameters)\n",
    "\n",
    "# Train test model\n",
    "train_test_model(clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM\n",
    "### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Choose some parameter combinations to try\n",
    "clf = LinearSVC()\n",
    "\n",
    "# Fit a model by providing X and y from training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Train test model\n",
    "train_test_model(clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_feature_importance = pd.DataFrame()\n",
    "df_feature_importance['feature'] = selected_features\n",
    "df_feature_importance['importance'] = clf.feature_importances_\n",
    "df_feature_importance.sort_values('importance',inplace=True)\n",
    "\n",
    "ax = df_feature_importance.plot.barh()\n",
    "t = np.arange(len(df_feature_importance['feature']))\n",
    "ax.set_yticks(t)\n",
    "ax.set_yticklabels(df_feature_importance['feature'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NonLinear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html# http:/ \n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Choose some parameter combinations to try\n",
    "parameters = {\n",
    "    'probability':True, # get simulated probability\n",
    "    'max_iter':2000\n",
    "    }\n",
    "clf = SVC(**parameters)    \n",
    "\n",
    "# Train test model\n",
    "train_test_model(clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_feature_importance = pd.DataFrame()\n",
    "df_feature_importance['feature'] = selected_features\n",
    "df_feature_importance['importance'] = clf.feature_importances_\n",
    "df_feature_importance.sort_values('importance',inplace=True)\n",
    "\n",
    "ax = df_feature_importance.plot.barh()\n",
    "t = np.arange(len(df_feature_importance['feature']))\n",
    "ax.set_yticks(t)\n",
    "ax.set_yticklabels(df_feature_importance['feature'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperParameter Tuning: Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Choose the type of classifier. \n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Choose some parameter combinations to try\n",
    "param_grid = {'n_estimators': [100,200], \n",
    "              'max_features': ['auto'], \n",
    "              'criterion': ['gini'],\n",
    "              'max_depth': [15,20,25], \n",
    "              'min_samples_split': [2],\n",
    "              'min_samples_leaf': [2,10,20],\n",
    "              'n_jobs':[-1]\n",
    "             }\n",
    "\n",
    "# Type of scoring used to compare parameter combinations\n",
    "acc_scorer = make_scorer(roc_auc_score)\n",
    "\n",
    "# Run the grid search\n",
    "# read theory\n",
    "grid_obj = GridSearchCV(clf, param_grid, cv=5, scoring=acc_scorer)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Set the clf to the best combination of parameters\n",
    "clf = grid_obj.best_estimator_\n",
    "\n",
    "# Fit the best algorithm to the data. \n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Train test model\n",
    "train_test_model(clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_feature_importance = pd.DataFrame()\n",
    "df_feature_importance['feature'] = selected_features\n",
    "df_feature_importance['importance'] = clf.feature_importances_\n",
    "df_feature_importance.sort_values('importance',inplace=True)\n",
    "\n",
    "ax = df_feature_importance.plot.barh()\n",
    "t = np.arange(len(df_feature_importance['feature']))\n",
    "ax.set_yticks(t)\n",
    "ax.set_yticklabels(df_feature_importance['feature'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
